import streamlit as st
import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import time
from optimizers import StochasticGradientDescent, GradientDescent, RMSProp, AdamW, Lion, Adan, MARS

st.set_page_config(
    page_title="AI Optimizers Playground",
    page_icon="üìä",
    layout="wide"
)

st.markdown("""
<style>
    .main {background-color: #f8f9fa;}
    .stButton>button {border-radius: 8px; padding: 8px 16px;}
    .stSelectbox, .stSlider {margin-bottom: 20px;}
    .metric-card {border-radius: 10px; padding: 15px; background: white; box-shadow: 0 4px 6px rgba(0,0,0,0.1);}
    .plot-container {margin-top: 30px;}
</style>
""", unsafe_allow_html=True)

st.title("üß† AI Optimizers Playground")
st.markdown("–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –ø–ª–æ—â–∞–¥–∫–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≤ –º–∞—à–∏–Ω–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏")

with st.sidebar:
    st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∏ —Ç–µ—Å—Ç–æ–≤–æ–π —Ñ—É–Ω–∫—Ü–∏–∏")

    optimizer = st.selectbox(
        "–í—ã–±–µ—Ä–∏—Ç–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä",
        ("SGD", "GD", "RMSProp", "AdamW", "Lion", "Adan", "MARS"),
        index=2
    )

    learning_rate = st.slider("–°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è", 0.0001, 0.1, 0.001, format="%.4f")
    momentum = st.slider("–ú–æ–º–µ–Ω—Ç—É–º (Œ≤)", 0.0, 1.0, 0.9)
    weight_decay = st.slider("Weight Decay", 0.0, 0.1, 0.01)
    iterations = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π", 10, 500, 100)

    st.markdown("---")
    test_func = st.selectbox(
        "–í—ã–±–µ—Ä–∏—Ç–µ —Ç–µ—Å—Ç–æ–≤—É—é —Ñ—É–Ω–∫—Ü–∏—é",
        ("Quadratic", "Rastrigin", "Rosenbrock", "Himmelblau")
    )
    resolution = st.slider("–†–∞–∑—Ä–µ—à–µ–Ω–∏–µ —Å–µ—Ç–∫–∏", 50, 300, 100)
    bounds = st.slider("–î–∏–∞–ø–∞–∑–æ–Ω –æ—Å–µ–π –¥–ª—è X –∏ Y", 1.0, 10.0, 5.0, step=0.5)

    st.markdown("---")
    show_surface = st.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç—å", value=True)
    show_3d = st.checkbox("3D –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è", value=True)
    realtime_update = st.checkbox("–†–µ–∂–∏–º —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏", value=True)

    if st.button("üîÑ –°–±—Ä–æ—Å–∏—Ç—å –∏ –Ω–∞—á–∞—Ç—å –∑–∞–Ω–æ–≤–æ"):
        st.experimental_rerun()

if 'history' not in st.session_state:
    st.session_state.history = {'loss': [], 'grad_norm': [], 'param_norm': [], 'iteration': []}

@st.cache_data
def generate_test_data(name, res, bnd):
    x = np.linspace(-bnd, bnd, res)
    y = np.linspace(-bnd, bnd, res)
    X, Y = np.meshgrid(x, y)
    if name == "Quadratic":
        Z = X**2 + Y**2
    elif name == "Rastrigin":
        Z = 10 * 2 + (X**2 - 10*np.cos(2*np.pi*X)) + (Y**2 - 10*np.cos(2*np.pi*Y))
    elif name == "Rosenbrock":
        Z = (1 - X)**2 + 100 * (Y - X**2)**2
    elif name == "Himmelblau":
        Z = (X**2 + Y - 11)**2 + (X + Y**2 - 7)**2
    return X, Y, Z

X, Y, Z = generate_test_data(test_func, resolution, bounds)

col1, col2 = st.columns([1, 1])

with col1:
    st.header("üìà –¢—Ä–∞–µ–∫—Ç–æ—Ä–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏")
    if optimizer == "SGD":
        opt = StochasticGradientDescent(learning_rate=learning_rate, momentum=momentum)
    elif optimizer == "GD":
        opt = GradientDescent(learning_rate=learning_rate)
    elif optimizer == "RMSProp":
        opt = RMSProp(learning_rate=learning_rate, momentum=momentum)
    elif optimizer == "AdamW":
        opt = AdamW(learning_rate=learning_rate, weight_decay=weight_decay)
    elif optimizer == "Lion":
        opt = Lion(learning_rate=learning_rate, weight_decay=weight_decay)
    elif optimizer == "Adan":
        opt = Adan(learning_rate=learning_rate, weight_decay=weight_decay)
    elif optimizer == "MARS":
        opt = MARS(learning_rate=learning_rate, momentum=momentum)

    start = np.random.uniform(-bounds, bounds, size=(2,))
    params = [start.copy()]
    trajectory = [start.copy()]
    losses = []
    plot_placeholder = st.empty()

    for i in range(iterations):
        grad = None
        if test_func == "Quadratic":
            grad = 2 * params[0]
        elif test_func == "Rastrigin":
            x0, y0 = params[0]
            grad = np.array([2*x0 + 20*np.pi*np.sin(2*np.pi*x0), 2*y0 + 20*np.pi*np.sin(2*np.pi*y0)])
        elif test_func == "Rosenbrock":
            x0, y0 = params[0]
            grad = np.array([-2*(1-x0) - 400*x0*(y0-x0**2), 200*(y0-x0**2)])
        elif test_func == "Himmelblau":
            x0, y0 = params[0]
            grad = np.array([4*x0*(x0**2 + y0 - 11) + 2*(x0 + y0**2 - 7), 2*(x0**2 + y0 - 11) + 4*y0*(x0 + y0**2 - 7)])
        grads = [grad]

        updated = opt.update(params, grads)
        trajectory.append(updated[0].copy())
        loss = opt._loss(updated[0], test_func) if hasattr(opt, '_loss') else np.sum(updated[0]**2)
        losses.append(loss)
        params = updated

        if realtime_update or i == iterations-1:
            df = pd.DataFrame({
                'x': [p[0] for p in trajectory],
                'y': [p[1] for p in trajectory],
                'loss': losses if len(losses)==len(trajectory) else [None]+losses,
                'iter': list(range(len(trajectory)))
            })
            if show_3d:
                fig = go.Figure(data=[
                    go.Surface(x=X, y=Y, z=Z, opacity=0.7, showscale=False) if show_surface else None,
                    go.Scatter3d(x=df['x'], y=df['y'], z=df['loss'], mode='markers+lines', marker=dict(size=4), line=dict(width=2))
                ])
                fig.update_layout(title=f"{optimizer} –Ω–∞ {test_func} (3D)")
            else:
                fig = px.contour(X, Y, Z, labels={'x':'X','y':'Y','z':'Z'}, title=f"{optimizer} –Ω–∞ {test_func} (2D)")
                fig.add_scatter(x=df['x'], y=df['y'], mode='markers+lines')
            plot_placeholder.plotly_chart(fig, use_container_width=True)
            if realtime_update:
                time.sleep(0.05)

with col2:
    st.header("üìä –ú–µ—Ç—Ä–∏–∫–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏")
    m1, m2, m3 = st.columns(3)
    with m1:
        st.markdown(f"**–§–∏–Ω–∞–ª—å–Ω—ã–π Loss:** {losses[-1]:.4f}")
    with m2:
        st.markdown(f"**–ò—Ç–µ—Ä–∞—Ü–∏–∏:** {iterations}")
    with m3:
        st.markdown(f"**LR:** {learning_rate:.4f}")

    st.subheader("–ò—Å—Ç–æ—Ä–∏—è Loss")
    df_loss = pd.DataFrame({'Loss': losses, 'Iteration': range(1, len(losses)+1)})
    fig_loss = px.line(df_loss, x='Iteration', y='Loss', title='Loss –Ω–∞ –ª–æ–≥. —à–∫–∞–ª–µ', log_y=True)
    st.plotly_chart(fig_loss, use_container_width=True)

    st.subheader("–ù–æ—Ä–º–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤")
    grad_norms = [np.linalg.norm(opt._last_grad) if hasattr(opt, '_last_grad') else None for _ in losses]
    df_grad = pd.DataFrame({'GradNorm': grad_norms, 'Iteration': range(1, len(grad_norms)+1)})
    fig_grad = px.line(df_grad, x='Iteration', y='GradNorm', title='–ù–æ—Ä–º–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤')
    st.plotly_chart(fig_grad, use_container_width=True)

st.markdown("---")
st.header(f"‚ÑπÔ∏è –û {test_func} –∏ {optimizer}")
if test_func == "Quadratic":
    st.markdown("**Quadratic** ‚Äî –ø—Ä–æ—Å—Ç–∞—è –ø–∞—Ä–∞–±–æ–ª–∏—á–µ—Å–∫–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–º –≥–ª–æ–±–∞–ª—å–Ω—ã–º –º–∏–Ω–∏–º—É–º–æ–º –≤ (0,0).")
elif test_func == "Rastrigin":
    st.markdown("**Rastrigin** ‚Äî –º—É–ª—å—Ç–∏-–º–æ–¥–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å –≥–ª–æ–±–∞–ª—å–Ω—ã–º –º–∏–Ω–∏–º—É–º–æ–º –≤ (0,0) –∏ –º–Ω–æ–∂–µ—Å—Ç–≤–æ–º –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–∏–Ω–∏–º—É–º–æ–≤.")
elif test_func == "Rosenbrock":
    st.markdown("**Rosenbrock** ‚Äî –Ω–µ–ª–∏–Ω–µ–π–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è-¬´–¥–æ–ª–∏–Ω–∞¬ª, —Å–ª–æ–∂–Ω–∞—è –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∏–∑-–∑–∞ —É–∑–∫–æ–π –∏–∑–æ–≥–Ω—É—Ç–æ–π –¥–æ–ª–∏–Ω—ã.")
elif test_func == "Himmelblau":
    st.markdown("**Himmelblau** ‚Äî –º—É–ª—å—Ç–∏-–º–æ–¥–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å —á–µ—Ç—ã—Ä—å–º—è –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–º–∏ –ª–æ–∫–∞–ª—å–Ω—ã–º–∏ –º–∏–Ω–∏–º—É–º–∞–º–∏.")

if optimizer == "SGD":
    st.markdown("**SGD** ‚Äî —Å—Ç–æ—Ö–∞—Å—Ç–∏—á–µ—Å–∫–∏–π –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫ —Å –º–æ–º–µ–Ω—Ç—É–º–æ–º.")
elif optimizer == "AdamW":
    st.markdown("**AdamW** ‚Äî Adam —Å decoupled weight decay.")
